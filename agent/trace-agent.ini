###################################################
# Global parameters used by the agent
[trace.config]
###################################################
# set it if you want to override os.HostName()
# FIXME? set to this so it works out of the box in devenv
hostname = ubuntu-1204.vagrantup.com

# environment value
# if not set that can be set via traces metadata and/or
# with host tags env:
# env = staging


###################################################
# Agent writer - API endpoint config
###################################################
[trace.api]
# where we send payloads, default to local
endpoint = http://localhost:8012

# your DD API key to auth
# one can also set a comma separated list of api keys to
# output to multiple accounts
api_key=apikey_2

# default to true, disable if you want dry-run mode
# enabled=false

# the maximum size of the payload buffer in bytes
# buffering is disabled if this setting is set to 0
payload_buffer_max_size=16777216

###################################################
# Agent concentrator - stats aggregation
###################################################
[trace.concentrator]
# The size of the buckets we concentrate the spans in
bucket_size_seconds=5

# The oldest span we accept in the intake before flushing
# and dropping late spans
oldest_span_cutoff_seconds=30

# Add another dimension to the aggregate stats grain
# the concentrator produces, these keys will be
# extracted as tags from the meta dict of spans
# extra_aggregators=


###################################################
# Agent sampler - what spans we keep? config
###################################################
[trace.sampler]
# Extra global sample rate to apply on all the traces
# This sample rate is combined to the sample rate from the sampler logic, still promoting interesting traces
# From 1 (no extra rate) to 0 (don't sample at all)
# extra_sample_rate=1

# Maximum number of traces per second to sample.
# The limit is applied over an average over a few minutes ; much bigger spikes are possible.
# Set to 0 to disable the limit.
# max_traces_per_second=10

###################################################
# Agent receiver - receives traces from our clients
# and queues for processing
###################################################
[trace.receiver]
# the port that the Receiver should listen
receiver_port=8126
# how many unique connections to allow during one 30 second lease period
connection_limit=2000

###################################################
# Trace writer - combines traces into payloads
# that are sent to Datadog servers
###################################################
[trace.writer.traces]
# Information about different traces is batched together for performance reasons. This setting controls the maximum
# amount of spans inside one of these batches. Bigger values lead to fewer but bigger payloads.
max_spans_per_payload=1000
# Period with which the agent forces flushes of payloads. In case the previous limit is not reached within this
# period, a payload with less than max_spans_per_payload will be sent.
flush_period_seconds=5
# Period with which the agent will send updated trace writer statistics to DD servers.
update_info_period_seconds=60
# For how many seconds should we keep traces queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: 20 minutes
queue_max_age_seconds=1200
# Maximum amount of trace data we can have queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: 256MB
queue_max_bytes=268435456
# Maximum amount of trace payloads we can have queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: Unlimited
queue_max_payloads=-1
# When we are unable to send traces to DD servers, retries will be attempted with various delays. Each retry delay
# is determined by a full-jitter exponential backoff that performs the following computation:
# delay = Random(0, Min(MaxDuration, (GrowthBase ^ NumRetries) * Base))
# The idea is that each consecutive retry for the same payload will, on average, take longer and longer until reaching
# MaxDuration and will also be desynchronized with retrial processes of other agents.
# The following parameters enable you to configure MaxDuration, Base and GrowthBase, respectively.
exp_backoff_max_duration_seconds=120
exp_backoff_base_milliseconds=200
exp_backoff_growth_base=2

###################################################
# Service writer - extracts service info from
# traces and sends it to Datadog servers.
###################################################
[trace.writer.services]
# Period with which the agent flushes service info to DD servers.
flush_period_seconds=5
# Period with which the agent will send updated service writer statistics to DD servers.
update_info_period_seconds=60
# When we are unable to send service info to DD servers, retries will be attempted with various delays. Each retry delay
# is determined by a full-jitter exponential backoff that performs the following computation:
# delay = Random(0, Min(MaxDuration, (GrowthBase ^ NumRetries) * Base))
# The idea is that each consecutive retry for the same payload will, on average, take longer and longer until reaching
# MaxDuration and will also be desynchronized with retrial processes of other agents.
# The following parameters enable you to configure MaxDuration, Base and GrowthBase, respectively.
exp_backoff_max_duration_seconds=120
exp_backoff_base_milliseconds=200
exp_backoff_growth_base=2

###################################################
# Stat writer - aggregates stats about traces
# and sends them to Datadog servers
###################################################
[trace.writer.stats]
# Period with which the agent will send updated stat writer statistics to DD servers.
update_info_period_seconds=60
# For how many seconds should we keep stats payloads queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: 20 minutes
queue_max_age_seconds=1200
# Maximum amount of stats data we can have queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: 256MB
queue_max_bytes=268435456
# Maximum amount of stats payloads we can have queued up in case we are unable to send them to DD servers.
# A value <= 0 disables this limit
# Default: Unlimited
queue_max_payloads=-1
# When we are unable to send stats to DD servers, retries will be attempted with various delays. Each retry delay
# is determined by a full-jitter exponential backoff that performs the following computation:
# delay = Random(0, Min(MaxDuration, (GrowthBase ^ NumRetries) * Base))
# The idea is that each consecutive retry for the same payload will, on average, take longer and longer until reaching
# MaxDuration and will also be desynchronized with retrial processes of other agents.
# The following parameters enable you to configure MaxDuration, Base and GrowthBase, respectively.
exp_backoff_max_duration_seconds=120
exp_backoff_base_milliseconds=200
exp_backoff_growth_base=2
